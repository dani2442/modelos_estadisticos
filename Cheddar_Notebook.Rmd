---
title: "Cheddar Faraway"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

### 1. Introducción

Tenenemos un conjunto de datos en el que se recogen observaciones de una cata de
quesos, nuestras variables son:   


**· Taste:** una valoración subjetiva de los jueces.   

**· Acetic:** la concentración de ácido acético en un queso de terminado en esca
la logarítmica  

**· H2S:** la concentración de sulfito de hidrógeno en escala logarítmica.

**· Lactic:** Concentración de ácido láctico

```{r}
library(faraway)
data(cheddar)
head(cheddar)
```

```{r}
sapply(cheddar, class)
```

Al ser todas numéricas no hay que hacer encoding a variables binarias

Usamos el número de observaciones para determinar los conjuntos de train y
test

```{r}
numObs <- dim(cheddar)[1]
numObs
```
Tenemos 30 observaciones, ¿Tenemos alguna en la que falten datos?
¿Tenemos outliers?  
Esto lo trataremos en la sección 4


```{r}
# Para asegurar que sea reproducible

set.seed(101)
sample <- sample.int(n = nrow(cheddar), 
                     size = floor(.7 * nrow(cheddar)), 
                     replace = F)
train <- cheddar[sample, ]
test <- cheddar[-sample, ]

```


### 2.Estudio y evaluación del modelo completo.  

Simplificamos nuestra notación para las variables, la que intentaremos predecir
es taste.

```{r}
T <- cheddar$taste
A <- cheddar$Acetic
H <- cheddar$H2S
L <- cheddar$Lactic
```


Definimos nuestro modelo completo:

```{r}
model.completo.lm <- lm(T~A+H+L, data=train)
plot(model.completo.lm)
```

```{r}
cor(train)
shapiro.test(resid(model.completo.lm))

```
Observamos que estamos en la hipótesis de que el error nuestro modelo se
distribuye de manera normal.  

¿Tienen todas las variables un impacto relevante en el modelo?

```{r}
summary(model.completo.lm)
betahat<- matrix(coef(model.completo.lm),ncol=1)
```

Obervamos el p-valor de A nos indica que con casi toda seguridad A no tiene 
impacto real en el modelo ( > 0.94)


```{r}
anova(model.completo.lm)
```

Los p-valores son lo suficientemente bajos como para rechazar varianza constante  

Una vez hemos concluido que aunque estamos en las hipótesis de regresión lineal
el modelo completo a pesar de ser el más complejo probablemente da resultados 
similares a otro más simple.


















