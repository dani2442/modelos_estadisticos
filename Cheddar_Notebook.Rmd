---
title: "Cheddar Faraway"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

# 1. Introducción

En un estudio de queso Cheddar realizado en el Valle de Latrobe (Victoria, Australia), se estudiaron muestras de queso en las que se analizó su composición química y fueron dadas a probar a distintos sujetos para que valoraran su sabor. Los valores asignados a cada queso son el resultado de combinar las distintas valoraciones. 

El DataFrame **cheddar** de la librería **faraway** consiste de 30 muestras de queso Cheddar en las que se ha medido el sabor (*taste*) y las concentraciones de ácido acético (*Acetic*), ácido sulfhídrico (*H2S*) y lactosa (*Lactic*).


Tenenemos un conjunto de datos en el que se recogen observaciones de una cata de
quesos, nuestras variables son:   


**· Taste:** una valoración subjetiva de los jueces.   

**· Acetic:** la concentración de ácido acético en un queso de terminado en esca
la logarítmica  

**· H2S:** la concentración de sulfito de hidrógeno en escala logarítmica.

**· Lactic:** Concentración de ácido láctico


```{r}
library(faraway)
data(cheddar)
head(cheddar)
```

```{r}
sapply(cheddar, class)
```

Al ser todas numéricas no hay que hacer encoding a variables binarias

Usamos el número de observaciones para determinar los conjuntos de train y
test

```{r}
numObs <- dim(cheddar)[1]
numObs
```
Tenemos 30 observaciones, ¿Tenemos alguna en la que falten datos?
¿Tenemos outliers?  
Esto lo trataremos en la sección 4


```{r}
# Para asegurar que sea reproducible

set.seed(101)
sample <- sample.int(n = nrow(cheddar), 
                     size = floor(.7 * nrow(cheddar)), 
                     replace = F)
train <- cheddar[sample, ]
test <- cheddar[-sample, ]

```


### 2.Estudio y evaluación del modelo completo.  

Simplificamos nuestra notación para las variables, la que intentaremos predecir
es taste.

```{r}
T <- cheddar$taste
A <- cheddar$Acetic
H <- cheddar$H2S
L <- cheddar$Lactic
```


Definimos nuestro modelo completo:

```{r}
model.completo.lm <- lm(T~A+H+L, data=train)
plot(model.completo.lm)
```

```{r}
cor(train)
shapiro.test(resid(model.completo.lm))

```
Observamos que estamos en la hipótesis de que el error nuestro modelo se
distribuye de manera normal.  

¿Tienen todas las variables un impacto relevante en el modelo?

```{r}
summary(model.completo.lm)
betahat<- matrix(coef(model.completo.lm),ncol=1)
```

Obervamos el p-valor de A nos indica que con casi toda seguridad A no tiene 
impacto real en el modelo ( > 0.94)


```{r}
anova(model.completo.lm)
```

Los p-valores son lo suficientemente bajos como para rechazar varianza constante  

Una vez hemos concluido que aunque estamos en las hipótesis de regresión lineal
el modelo completo a pesar de ser el más complejo probablemente da resultados 
similares a otro más simple.  

### 3.¿Cuál es el mejor modelo?

#### 3.1. Método Backward  

Partimos del modelo completo estudiado en la sección anterior y aplicamos con
\alpha = 0.05.

```{r}
drop1(model.completo.lm, test = "F")
```
    
Quitamos Acetic del modelo debido que su p-valor es > 0.05 
```{r}
model.update1 <- update(model.completo.lm, . ~ . - A)
drop1(model.update1, test = "F")
```

Todos los p-valores son menores que \alpha = 0.05 por lo tanto hemos concluido

```{r}
model.backward.lm <- lm(T~H+L, data = train)
summary(model.backward.lm)
```

#### 3.1. Método Backward 


```{r}
SCOPE<-(~.+A + H + L)
model.inicial <- lm(T~1,data=train)
add1(model.inicial,scope=SCOPE,test="F")

```


Actualizamos añadiendo el de menor pvalue
```{r}
model.updatei1 <- update(model.inicial, .~. +H)
add1(model.updatei1,scope=SCOPE,test="F")
```


```{r}
model.updatei2<-update(model.updatei1, .~. +L)
add1(model.updatei2,scope=SCOPE,test="F")
```
Ahora es el modelo final, igual vale con alpha de minimo 0.02

```{r}
model.forward.lm<-lm(T~H+L, data=train)
summary(model.forward.lm)
```

#### 3.3.Construcción por criterios

Necesitaremos la librería leaps para esta subsección.

```{r}
library(leaps)
```


```{r}
models<-regsubsets(taste~., data=train)
summary(models)
```


```{r}
MR2adj<-summary(models)$adjr2
MR2adj
which.max(MR2adj)
summary(models)$which[2, ]
```

```{r}
model.final3<-lm(taste~H2S+Lactic, data=train)
plot(models,scale="adjr2")
```
Se busca el máximo y se ve como crece

```{r}
MCp <-summary(models)$cp
which.min(MCp)
summary(models)$which[2, ]
model.final4<-lm(taste~H2S+Lactic, data=train)
plot(models,scale="Cp")
```

Se busca el minimo y se ve como decrece
```{r}
MBIC <-summary(models)$bic
which.min(MBIC)
summary(models)$which[2, ]
model.final5<-lm(taste~H2S+Lactic, data=train)
plot(models,scale="bic")
```

```{r}
library(MASS)
model.completo.lm <- lm(taste~., data=train)
SCOPE <-(~.)
stepAIC(model.completo.lm, scope=SCOPE, k=2)
```

Obsérvese todos los metodos por criterios y por pasos nos llevan al mismo modelo


#### 4- Diagnostic
```{r}

```



